{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfc6 Prompt Engineering Competition",
        "",
        "Welcome to the **Prompt Competition Activity**! This is a hands-on exercise where you'll experiment with OpenAI API parameters to achieve specific creative outcomes.",
        "",
        "## The Challenge",
        "",
        "Everyone gets the **same prompt**: **\"Describe a pencil\"**",
        "",
        "But you'll adjust different parameters to create wildly different outputs!",
        "",
        "## Competition Categories",
        "",
        "- \ud83e\udd71 **Most Boring** - Consistent and predictable",
        "- \ud83c\udfa8 **Most Creative** - Unexpected and imaginative",
        "- \ud83d\udcdd **Most Concise** - Short and sweet",
        "- \ud83d\udcda **Most Verbose** - Long and elaborate",
        "- \ud83c\udfaf **Most Focused** - Precise and on-point",
        "- \ud83c\udfb2 **Most Random** - Wild and unpredictable",
        "",
        "## How It Works",
        "",
        "1. Each category has a starter code template",
        "2. Experiment with the parameters",
        "3. Run your code and see the results",
        "4. Compare outputs with your classmates",
        "5. Vote for the best in each category!",
        "",
        "Let's begin! \ud83d\ude80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup",
        "",
        "First, let's import the necessary libraries and set up our helper functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries",
        "import os",
        "from openai import OpenAI",
        "import time",
        "",
        "# Initialize OpenAI client",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))",
        "",
        "# Set default model",
        "MODEL = \"gpt-4o-mini\"",
        "",
        "print(\"\u2705 Setup complete! Ready for the competition!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper Functions",
        "",
        "These functions will help us display results and track token usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_openai_with_params(prompt, temperature=0.7, max_tokens=None, top_p=1.0, ",
        "                            frequency_penalty=0.0, presence_penalty=0.0, seed=None):",
        "    \"\"\"Call OpenAI with specific parameters - perfect for experimentation!\"\"\"",
        "    try:",
        "        params = {",
        "            \"model\": MODEL,",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],",
        "            \"temperature\": temperature,",
        "            \"top_p\": top_p,",
        "            \"frequency_penalty\": frequency_penalty,",
        "            \"presence_penalty\": presence_penalty",
        "        }",
        "        ",
        "        if max_tokens:",
        "            params[\"max_tokens\"] = max_tokens",
        "        if seed is not None:",
        "            params[\"seed\"] = seed",
        "            ",
        "        response = client.chat.completions.create(**params)",
        "        return response.choices[0].message.content",
        "    except Exception as e:",
        "        return f\"Error: {str(e)}\"",
        "",
        "def display_result(category, response, params):",
        "    \"\"\"Display competition results with formatting\"\"\"",
        "    print(\"\\n\" + \"=\"*70)",
        "    print(f\"\ud83c\udfc6 {category}\")",
        "    print(\"=\"*70)",
        "    print(f\"\\n\ud83d\udccb Parameters:\")",
        "    for key, value in params.items():",
        "        print(f\"   {key}: {value}\")",
        "    print(f\"\\n\ud83d\udcdd Output ({len(response)} characters):\")",
        "    print(\"-\"*70)",
        "    print(response)",
        "    print(\"-\"*70)",
        "    print(f\"Token estimate: ~{len(response)//4} tokens\\n\")",
        "",
        "def count_tokens_approx(text):",
        "    \"\"\"Approximate token count\"\"\"",
        "    return len(text) // 4",
        "",
        "print(\"\u2705 Helper functions loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfc1 Competition Categories",
        "",
        "Time to compete! Each category below has a starter template. **Experiment with the parameters** to achieve the goal.",
        "",
        "### Base Prompt",
        "",
        "Remember, everyone uses the same prompt: **\"Describe a pencil\"**",
        "",
        "Now let's see how different parameters create completely different outputs!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 1: \ud83e\udd71 Most Boring",
        "",
        "**Goal**: Create the most consistent, predictable, \"boring\" response possible.",
        "",
        "**Strategy**: Use temperature=0 for deterministic outputs. The model will always choose the most likely next token.",
        "",
        "**Your Task**: Run this code and see how consistent it is. Try running it multiple times!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most Boring Configuration",
        "prompt = \"Describe a pencil\"",
        "",
        "# Parameters for boring/consistent output",
        "params = {",
        "    \"temperature\": 0,        # Maximum consistency",
        "    \"max_tokens\": 100,",
        "    \"top_p\": 1.0,",
        "    \"frequency_penalty\": 0.0,",
        "    \"presence_penalty\": 0.0",
        "}",
        "",
        "# Run it!",
        "response = call_openai_with_params(prompt, **params)",
        "display_result(\"Most Boring (Consistent)\", response, params)",
        "",
        "# \ud83d\udca1 TIP: Run this cell multiple times - notice how similar the outputs are!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 2: \ud83c\udfa8 Most Creative",
        "",
        "**Goal**: Generate the most unexpected, creative, imaginative response.",
        "",
        "**Strategy**: High temperature + penalties to avoid repetition = maximum creativity!",
        "",
        "**Your Task**: Experiment with temperature (try 1.5-2.0) and penalties. Can you make it even more creative?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most Creative Configuration",
        "prompt = \"Describe a pencil\"",
        "",
        "# Parameters for creative output",
        "params = {",
        "    \"temperature\": 1.8,       # High randomness",
        "    \"max_tokens\": 150,",
        "    \"top_p\": 0.95,",
        "    \"frequency_penalty\": 0.7, # Avoid repetition",
        "    \"presence_penalty\": 0.6   # Encourage new topics",
        "}",
        "",
        "# Run it!",
        "response = call_openai_with_params(prompt, **params)",
        "display_result(\"Most Creative\", response, params)",
        "",
        "# \ud83c\udfa8 EXPERIMENT: Try changing temperature to 2.0 or adjusting penalties!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 3: \ud83d\udcdd Most Concise",
        "",
        "**Goal**: Create the shortest possible complete response.",
        "",
        "**Strategy**: Severely limit max_tokens to force brevity.",
        "",
        "**Your Task**: Find the sweet spot - short but still meaningful. Too short and it's incomplete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most Concise Configuration",
        "prompt = \"Describe a pencil\"",
        "",
        "# Parameters for concise output",
        "params = {",
        "    \"temperature\": 0.5,",
        "    \"max_tokens\": 20,          # Very short!",
        "    \"top_p\": 1.0,",
        "    \"frequency_penalty\": 0.0,",
        "    \"presence_penalty\": 0.0",
        "}",
        "",
        "# Run it!",
        "response = call_openai_with_params(prompt, **params)",
        "display_result(\"Most Concise\", response, params)",
        "",
        "# \ud83d\udcdd EXPERIMENT: Try max_tokens between 10-30. What's the minimum that still makes sense?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 4: \ud83d\udcda Most Verbose",
        "",
        "**Goal**: Generate the longest, most elaborate response possible.",
        "",
        "**Strategy**: High max_tokens + negative penalties to encourage elaboration.",
        "",
        "**Your Task**: Make it as detailed and wordy as possible!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most Verbose Configuration",
        "prompt = \"Describe a pencil in great detail\"  # You can modify the prompt slightly!",
        "",
        "# Parameters for verbose output",
        "params = {",
        "    \"temperature\": 0.8,",
        "    \"max_tokens\": 500,           # Allow long responses",
        "    \"top_p\": 1.0,",
        "    \"frequency_penalty\": -0.5,   # Allow some repetition",
        "    \"presence_penalty\": -0.5     # Encourage staying on topic",
        "}",
        "",
        "# Run it!",
        "response = call_openai_with_params(prompt, **params)",
        "display_result(\"Most Verbose\", response, params)",
        "",
        "# \ud83d\udcda EXPERIMENT: Try adding more detail requests to the prompt!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 5: \ud83c\udfaf Most Focused",
        "",
        "**Goal**: Generate the most precise, focused response without tangents.",
        "",
        "**Strategy**: Low top_p means only consider the most likely tokens = stay on topic!",
        "",
        "**Your Task**: Create a laser-focused description that doesn't wander."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most Focused Configuration",
        "prompt = \"Describe a pencil\"",
        "",
        "# Parameters for focused output",
        "params = {",
        "    \"temperature\": 0.3,",
        "    \"max_tokens\": 100,",
        "    \"top_p\": 0.1,              # Only top 10% of likely tokens",
        "    \"frequency_penalty\": 0.0,",
        "    \"presence_penalty\": 0.0",
        "}",
        "",
        "# Run it!",
        "response = call_openai_with_params(prompt, **params)",
        "display_result(\"Most Focused\", response, params)",
        "",
        "# \ud83c\udfaf EXPERIMENT: Compare top_p=0.1 vs top_p=0.9 - see the difference!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 6: \ud83c\udfb2 Most Random",
        "",
        "**Goal**: Generate the most unpredictable, wild response possible.",
        "",
        "**Strategy**: Maximum temperature = maximum chaos!",
        "",
        "**Your Task**: Push temperature to the limit. How weird can you make it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most Random Configuration",
        "prompt = \"Describe a pencil\"",
        "",
        "# Parameters for random output",
        "params = {",
        "    \"temperature\": 2.0,        # Maximum randomness!",
        "    \"max_tokens\": 150,",
        "    \"top_p\": 1.0,",
        "    \"frequency_penalty\": 0.5,",
        "    \"presence_penalty\": 0.5",
        "}",
        "",
        "# Run it!",
        "response = call_openai_with_params(prompt, **params)",
        "display_result(\"Most Random\", response, params)",
        "",
        "# \ud83c\udfb2 EXPERIMENT: Run this multiple times - each output should be very different!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\uddea Your Own Experiment",
        "",
        "Now it's your turn! Create your own category and experiment with any combination of parameters.",
        "",
        "**Ideas:**",
        "- Most poetic",
        "- Most technical",
        "- Most humorous",
        "- Most philosophical",
        "- Most like a 5-year-old would say it",
        "",
        "**Parameters you can adjust:**",
        "- `temperature`: 0.0 to 2.0 (randomness)",
        "- `max_tokens`: 10 to 1000 (length limit)",
        "- `top_p`: 0.0 to 1.0 (nucleus sampling)",
        "- `frequency_penalty`: -2.0 to 2.0 (penalize repetition)",
        "- `presence_penalty`: -2.0 to 2.0 (encourage new topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR EXPERIMENT!",
        "prompt = \"Describe a pencil\"  # You can modify this too!",
        "",
        "# YOUR parameters - experiment!",
        "params = {",
        "    \"temperature\": 0.7,        # ADJUST ME!",
        "    \"max_tokens\": 100,         # ADJUST ME!",
        "    \"top_p\": 1.0,              # ADJUST ME!",
        "    \"frequency_penalty\": 0.0,  # ADJUST ME!",
        "    \"presence_penalty\": 0.0    # ADJUST ME!",
        "}",
        "",
        "# Run your experiment!",
        "response = call_openai_with_params(prompt, **params)",
        "display_result(\"YOUR CATEGORY NAME\", response, params)",
        "",
        "# \ud83d\udcad What were you trying to achieve? Did it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Results Comparison & Discussion",
        "",
        "Now that you've experimented with different parameters, let's reflect on what you learned.",
        "",
        "### Discussion Questions",
        "",
        "**1. Which parameters had the biggest impact on the output?**",
        "   - Temperature?",
        "   - max_tokens?",
        "   - top_p?",
        "   - Penalties?",
        "",
        "**2. Which category was easiest to achieve?**",
        "   - Why do you think that is?",
        "",
        "**3. Which category was hardest?**",
        "   - What made it challenging?",
        "",
        "**4. What surprised you?**",
        "   - Any unexpected results?",
        "",
        "**5. When would you use these different parameter settings in real projects?**",
        "   - Boring/Consistent: ___________________",
        "   - Creative: ___________________",
        "   - Concise: ___________________",
        "   - Verbose: ___________________",
        "   - Focused: ___________________",
        "   - Random: ___________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Your Results",
        "",
        "Use this space to paste your best outputs and compare with your classmates!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Record your team's best results here!",
        "",
        "results_summary = {",
        "    \"Most Boring\": \"PASTE YOUR OUTPUT HERE\",",
        "    \"Most Creative\": \"PASTE YOUR OUTPUT HERE\",",
        "    \"Most Concise\": \"PASTE YOUR OUTPUT HERE\",",
        "    \"Most Verbose\": \"PASTE YOUR OUTPUT HERE\",",
        "    \"Most Focused\": \"PASTE YOUR OUTPUT HERE\",",
        "    \"Most Random\": \"PASTE YOUR OUTPUT HERE\",",
        "    \"Your Category\": \"PASTE YOUR OUTPUT HERE\"",
        "}",
        "",
        "# Display summary",
        "print(\"\\n\" + \"=\"*70)",
        "print(\"\ud83c\udfc6 YOUR COMPETITION RESULTS\")",
        "print(\"=\"*70)",
        "for category, result in results_summary.items():",
        "    if result != \"PASTE YOUR OUTPUT HERE\":",
        "        print(f\"\\n{category}:\")",
        "        print(f\"  {result[:100]}...\" if len(result) > 100 else f\"  {result}\")",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\uddf3\ufe0f Voting Time!",
        "",
        "Time to vote for the best output in each category!",
        "",
        "### Voting Instructions",
        "",
        "1. Each team/student shares their best output for each category",
        "2. Class votes for the winner of each category",
        "3. Winners explain their parameter choices",
        "",
        "### Voting Ballot",
        "",
        "Fill in the winner for each category:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VOTING RESULTS",
        "voting_results = {",
        "    \"Most Boring\": {",
        "        \"winner\": \"Team/Student Name\",",
        "        \"why\": \"What made it the best?\"",
        "    },",
        "    \"Most Creative\": {",
        "        \"winner\": \"Team/Student Name\",",
        "        \"why\": \"What made it the best?\"",
        "    },",
        "    \"Most Concise\": {",
        "        \"winner\": \"Team/Student Name\",",
        "        \"why\": \"What made it the best?\"",
        "    },",
        "    \"Most Verbose\": {",
        "        \"winner\": \"Team/Student Name\",",
        "        \"why\": \"What made it the best?\"",
        "    },",
        "    \"Most Focused\": {",
        "        \"winner\": \"Team/Student Name\",",
        "        \"why\": \"What made it the best?\"",
        "    },",
        "    \"Most Random\": {",
        "        \"winner\": \"Team/Student Name\",",
        "        \"why\": \"What made it the best?\"",
        "    }",
        "}",
        "",
        "# Display winners",
        "print(\"\\n\" + \"=\"*70)",
        "print(\"\ud83c\udfc6 COMPETITION WINNERS!\")",
        "print(\"=\"*70)",
        "for category, info in voting_results.items():",
        "    print(f\"\\n{category}: {info['winner']}\")",
        "    print(f\"  Why: {info['why']}\")",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf93 Key Takeaways",
        "",
        "Congratulations on completing the Prompt Competition! Here's what you've learned about AI parameters.",
        "",
        "### Parameter Cheat Sheet",
        "",
        "| Parameter | Range | Effect | Use When |",
        "|-----------|-------|--------|----------|",
        "| **temperature** | 0.0 - 2.0 | Controls randomness | 0 for consistency, 1.5+ for creativity |",
        "| **max_tokens** | 1 - 4000+ | Limits response length | Set based on desired output size |",
        "| **top_p** | 0.0 - 1.0 | Nucleus sampling | Lower for focus, higher for variety |",
        "| **frequency_penalty** | -2.0 - 2.0 | Penalizes token repetition | Positive to reduce repetition |",
        "| **presence_penalty** | -2.0 - 2.0 | Encourages new topics | Positive for diverse topics |",
        "",
        "### Real-World Applications",
        "",
        "**Consistent/Boring (temp=0):**",
        "- Data extraction",
        "- Classification tasks",
        "- Structured output",
        "- Testing and debugging",
        "",
        "**Creative (temp=1.5-2.0):**",
        "- Content generation",
        "- Brainstorming",
        "- Creative writing",
        "- Marketing copy",
        "",
        "**Concise (low max_tokens):**",
        "- Summaries",
        "- Titles and headlines",
        "- Quick answers",
        "- Mobile applications",
        "",
        "**Verbose (high max_tokens):**",
        "- Detailed explanations",
        "- Documentation",
        "- Educational content",
        "- Comprehensive analysis",
        "",
        "**Focused (low top_p):**",
        "- Technical accuracy",
        "- Fact-based responses",
        "- When staying on topic is critical",
        "",
        "**Random (high temp):**",
        "- Exploring possibilities",
        "- Generating variations",
        "- Creative experimentation",
        "",
        "### Remember",
        "",
        "> **Prompt engineering is about experimentation!**",
        "> ",
        "> There's no single \"right\" parameter setting - it depends on your use case, goals, and desired output.",
        "",
        "### Next Steps",
        "",
        "1. Practice with real prompts from your projects",
        "2. Build a library of parameter presets",
        "3. Test with different models",
        "4. Keep learning in the main lesson notebook!",
        "",
        "---",
        "",
        "**Great work! You're now a prompt parameter expert! \ud83c\udf89**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}